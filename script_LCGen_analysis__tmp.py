#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Scripts for analyzing of phantom outputs.

This script generate lightcurves (LC) by doing radiative transfer on a grid.


-------------------------------------------------------------------------------

Side note: Remember to limit line length to 79 characters according to PEP-8
    https://peps.python.org/pep-0008/#maximum-line-length    
which is the length of below line of '-' characters.

-------------------------------------------------------------------------------

"""

import numpy as np
from numpy import pi
from numpy import typing as npt
from astropy import units
from astropy import constants as const
from clmuphantomlib.log import is_verbose, say
from clmuphantomlib import MyPhantomDataFrames, get_eos, get_eos_opacity
from clmuphantomlib.eos   import EoS_MESA_opacity
from clmuphantomlib.units_util import get_val_in_unit
from _sharedFuncs import mpdf_read

def gen_Tscales(
    job_name: str,
    T_ph : units.Quantity,
    R_ph : units.Quantity,
    do_save: bool = True,
    params : dict = {'X':0.7, 'Z':0.0},
    verbose: int = 3,
) -> MyPhantomDataFrames:
    """Generate scales at t=0 to scale down temperatures of outter particles.
    
    So temperatures outside the MESA-calculated photosphere
    is scaled down to the MESA values.
    This can be applied to later times,
    so we can see how much the effect of the instable init
    of MESA -> Phantom dump can be.

    ---------------------------------------------------------------------------
    """
    mpdf = mpdf_read(
        job_name, file_index=0, reset_xyz_by='', params=params,
        calc_params=['R1'], verbose=verbose)

    # particle indexes
    inds = mpdf.get_val('R1') > R_ph
    scales = np.zeros(
        np.count_nonzero(inds),
        dtype=[('iorig', np.int64), ('T_scale', np.float64)])
    # particle ids
    #    retrieve back inds from ids by inds_new = mpdf.data['gas']['iorig'].isin(ids)
    scales['iorig'] = mpdf.data['gas']['iorig'][inds]
    scales['T_scale'] = (T_ph / mpdf.get_val('T')[inds]).to_value(
        units.dimensionless_unscaled)
    # scale down only, do not heat the particles
    scales['T_scale'][scales['T_scale'] > 1.] = 1.

    if do_save:
        filename = f"{job_name}_Tscales.npy"
        say('note', None, verbose, f"Saving to {filename}")
        with open(filename, 'wb') as fp:
            np.save(fp, scales)

    return scales


import numpy as np
from numpy import pi
from astropy import units
from astropy import constants as const
import matplotlib.pyplot as plt
from matplotlib.typing import ColorType
import matplotlib as mpl
mpl.use('Agg')
from numba import jit,njit, prange
import sarracen
import itertools
from scipy import integrate, fft
from scipy.spatial import kdtree
from datetime import datetime
# fix weird moviepy cannot find my ffmpeg exe error
try: from moviepy import editor
except RuntimeError: import os; os.environ["IMAGEIO_FFMPEG_EXE"] = "/usr/bin/ffmpeg"
from moviepy.editor import ImageSequenceClip, concatenate_videoclips
import gc
#from os import path




# import my modules listed in ./main/

import clmuphantomlib as mupl
from clmuphantomlib            import MyPhantomDataFrames, get_eos
from clmuphantomlib.log        import is_verbose, say
from clmuphantomlib.settings   import DEFAULT_SETTINGS as settings
from clmuphantomlib.units_util import get_val_in_unit, set_as_quantity #, get_units_field_name, get_units_cgs
from clmuphantomlib.io         import json_dump, json_load
from clmuphantomlib.eos.mesa   import EoS_MESA_opacity
from clmuphantomlib.light      import get_optical_depth_by_ray_tracing_3D, get_photosphere_on_ray

from multiprocessing import cpu_count, Pool #Process, Queue
NPROCESSES = 1 if cpu_count() is None else max(cpu_count(), 1)




# settings
#
#   imported from script_input.py file


from script_LCGen__input import verbose, verbose_loop, interm_dir, output_dir, unitsOut, SPEC_DIST, PHOTOSPHERE_TAU, JOB_PROFILES_DICT
from _sharedFuncs import mpdf_read, pa_read_energy, pa_read_ev

# remove temp flag
interm_dir = interm_dir.split('test_')[0]
interm_dir = interm_dir.split('Tscale_')[0]
interm_dir = interm_dir.split('Tcut_')[0]
interm_dir = interm_dir.split('Tdelete_')[0]


unitsOutTxt = {  key  : unitsOut[key].to_string('latex_inline') for key in unitsOut.keys() }

spec_dist = SPEC_DIST

# set metadata
with open("_metadata__input.json", 'r') as f:
    metadata = json_load(f)
metadata['Title'] = "Getting light curves by intergrating across a grid of rays"
metadata['Description'] = f"""Getting light curves by intergrating across a grid of rays with the same directions
for dump file data generated by phantom
"""


plt.rcParams.update({'font.size': 20})
if __name__ == '__main__' and is_verbose(verbose, 'note'):
    # remember to check if name is '__main__' if you wanna say anything
    #    so when you do multiprocessing the program doesn't freak out
    say('note', None, verbose, f"{interm_dir = }")
    say('note', None, verbose, f"Will use {NPROCESSES} processes for parallelization")





from clmuphantomlib.log import say, is_verbose
from clmuphantomlib.geometry import get_dist2_between_2pt, get_closest_pt_on_line
from clmuphantomlib.sph_interp import get_sph_interp, get_h_from_rho, get_no_neigh, _get_sph_interp_phantom_np
from clmuphantomlib.units_util import set_as_quantity, set_as_quantity_temperature, get_units_field_name
from clmuphantomlib.eos   import EoS_Base
from clmuphantomlib.light import integrate_along_ray_grid, integrate_along_ray_gridxy

#  import (general)
import numpy as np
import numba
from numba import jit, njit, prange
import sarracen
from scipy.stats import linregress

from clmuphantomlib.geometry import get_dist2_from_pts_to_line, get_dist2_from_pt_to_line_nb, get_ray_unit_vec, get_rays_unit_vec




# load from matin script

# backup-ed old codes
from script_LCGen import integrate_along_ray, integrate_error_along_ray
# test codes (alpha)
from script_LCGen import _integrate_along_ray_gridxy_sub_parallel_analysis_test
# actual code
from script_LCGen import _integrate_along_ray_gridxy_sub_parallel_analysis, _integrate_along_ray_gridxy_sub_parallel_err_ind
# integrations
from script_LCGen import integrate_along_ray_gridxy_ind, integrate_along_ray_gridxy_err_ind
# rays grid generation, plotting
from script_LCGen import get_xy_grids_of_rays, plot_imshow
# error estimation
from script_LCGen import get_sph_neighbours, get_sph_error







def plot_heat(
    no_xy: tuple[int, int],
    rays: units.Quantity|np.ndarray,
    data: units.Quantity|np.ndarray,
    fig = None, ax = None, plot_cbar: bool= True,
    job_profile  : dict= None,
    file_index   : int = -1,
    title_suffix : str ="",
    notes        : dict= None,
    data_label   : str ="",
    save_label   : str ="",
    ylabelpad    : None|float = None,
    xyzs         : str|list[str] = 'xyz',
    out_exts     : list[str] = ['pdf', 'png'],
    nlevel       : int = 100,
    levels       : None|list[float] = None,
    ticks        : None|int|list[float] = None,
    cbar_num_fmt : None|type(abs) = None,
    facecolor    : None|ColorType = None,
    text_color   : None|str = None,
    xylim : None|tuple[float, float] = None,
    norm=None,
    cmap=None,
    output_dir:str|None=None,
    verbose = 3,
):
    """Plotting a heatmap (contourf) of 1D data located at rays

    cbar_num_fmt: function
        colorbar label format.
        e.g. lambda x, pos: f"{x:.2e}"
    
    """


    if not isinstance(data, units.Quantity):
        data = set_as_quantity(data, units.dimensionless_unscaled)

    if not isinstance(rays, units.Quantity):
        rays = set_as_quantity(rays, units.dimensionless_unscaled)

    if job_profile is None:
        job_profile = {
            'plot_title_suffix': '',
            'nickname'         : '',
        }

    Xs = rays[:, 0, 0]
    Ys = rays[:, 0, 1]
    rays_val = rays.reshape(*no_xy, *rays.shape[1:]).value
    extent = (
        rays_val[ 0, 0, 0, 0] - (rays_val[ 1, 0, 0, 0] - rays_val[ 0, 0, 0, 0])/2,
        rays_val[-1,-1, 0, 0] + (rays_val[-1,-1, 0, 0] - rays_val[-2,-1, 0, 0])/2,
        rays_val[ 0, 0, 0, 1] - (rays_val[ 0, 1, 0, 1] - rays_val[ 0, 0, 0, 1])/2,
        rays_val[-1,-1, 0, 1] + (rays_val[-1,-1, 0, 1] - rays_val[-1,-2, 0, 1])/2,
    )
    if xylim is None: xylim  = max([abs(it) for it in extent])
    xylims = (-xylim, xylim)
    if   isinstance(norm, mpl.colors.LogNorm):
        levels = np.logspace(np.log10(norm.vmin), np.log10(norm.vmax), nlevel+1)
    elif isinstance(norm, mpl.colors.Normalize):
        levels = np.linspace(norm.vmin, norm.vmax, nlevel+1) if levels is None else levels
        if isinstance(ticks, int):
            ticks  = np.linspace(norm.vmin, norm.vmax, ticks+1)
    else:
        levels = nlevel if levels is None else levels
        

    if fig is None or ax is None:
        fig, ax = plt.subplots(figsize=(10, 8))
    
    
    #cax = ax.imshow(data.reshape(no_xy).T.value, norm=norm, cmap=cmap, origin='lower', extent=extent)
    if facecolor is None: facecolor = plt.get_cmap(cmap).get_under()
    ax.set_facecolor(facecolor)
    cax = ax.contourf(Xs.reshape(no_xy).value, Ys.reshape(no_xy).value, data.reshape(no_xy).value, levels, norm=norm, cmap=cmap, extend='both')
    for c in cax.collections:
        c.set_edgecolor("face")
    if plot_cbar:
        cbar= fig.colorbar(cax, label=f"{data_label} / {data.unit.to_string('latex_inline')}", ticks=ticks, format=cbar_num_fmt)
    ax.set_xlabel(f"${xyzs[0]}$ / {rays.unit.to_string('latex_inline')}")
    ax.set_ylabel(f"${xyzs[1]}$ / {rays.unit.to_string('latex_inline')}", labelpad=ylabelpad)
    ax.set_xlim(xylims)
    ax.set_ylim(xylims)
    ax.set_title('')
    if notes is not None:
        ax.text(
            0.98, 0.98,
            f"Time = {notes['time']:.1f}\n",
            # + f" $L$ = {notes['lum' ]:.0f}",
            color = text_color,
            ha = 'right', va = 'top',
            transform=ax.transAxes,
        )

    no_xy_txt = 'x'.join([f'{i}' for i in no_xy])
    outfilename_noext = f"{output_dir}heat_{job_profile['nickname']}_{file_index:05d}_{''.join(xyzs)}_{save_label}_{no_xy_txt}"
    outfilenames = []

    # write pdf
    for out_ext in out_exts:
        outfilename = f"{outfilename_noext}.{out_ext}"
        if out_ext == 'pdf':
            ax.set_title('')
        else:
            ax.set_title(f"Heatmap of {data_label}\n{job_profile['plot_title_suffix']}")
        fig.savefig(outfilename)
        outfilenames.append(outfilename)
        if is_verbose(verbose, 'note'):
            say('note', None, verbose, f"Fig saved to {outfilename}.")
        
    return fig, cax, outfilenames

## example
#fig, ax = plot_imshow(
#    no_xy, rays * units.Rsun, anses, data_label="$I$", save_label="I_xyz",
#    job_profile=job_profile, file_index=file_index, output_dir=output_dir)




# settings

output_dir = f'../fig/20240222_LCGen/'
xyzs_list = None #['xyz', 'xzy'] #None

unit_I = units.erg/units.cm**2/units.s/units.rad**2

















### Getting initial MESA profile vs relaxed phantom profile

def plot_stuff(
    stuff_dict: dict,
    x_name: str, y_name: str, mpdf, job_profile,
    xlim: tuple[float, float]=(1., 1.e3),
    label='',
    ylim = None,
):
    plt.close()
    fig, ax = plt.subplots(figsize=(10, 8))
    xs, ys = stuff_dict[x_name], stuff_dict[y_name]
    if isinstance(xs, units.Quantity): xs = xs.value
    if isinstance(ys, units.Quantity): ys = ys.value
    if xlim is None: mask = np.ones_like(xs, dtype=np.bool_)
    else: mask = np.logical_and(xlim[0] < xs, xs < xlim[1])
    # ax.loglog(xs[mask], ys[mask], '.', label=label)
    ax.semilogy(xs[mask], ys[mask], '.', label=label)
    ax.set_xlabel(f"{x_name} / {stuff_dict[x_name].unit.to_string('latex_inline')}")
    ax.set_ylabel(f"{y_name} / {stuff_dict[y_name].unit.to_string('latex_inline')}")
    ax.text(
        0.98, 0.98, f"Time = {mpdf.get_time()}",
        ha = 'right', va = 'top', transform=ax.transAxes,
    )
    # ax.set_title(f"scatter plot of all particles\n{job_profile['plot_title_suffix']}")
    ax.set_xlim(xlim)
    return fig, ax, mask


def read_mesa_data(
    eos_opacity,
    filename = '../dustystar/AGB_th.data',
):
    mesa_data = np.loadtxt(
        filename, skiprows=6,
        usecols=(2, 3, 4, 9, 10, 11, 12, 19),
        dtype=[
            ('log10_R1', np.double),
            ('log10_T', np.double),
            ('log10_rho', np.double),
            ('R1_cm', np.double),
            ('mass_g', np.double),
            ('temp', np.double),
            ('rho', np.double),
            ('lum', np.double)]
    )
    stuff_mesa = {
        'R1': (mesa_data['R1_cm'] * units.cm).to(units.Rsun),
        'T' : mesa_data['temp'] * units.K,
        'lum' : mesa_data['lum'] * units.Lsun,
        'rho' : mesa_data['rho'] * (units.g/units.cm**3),
    }
    del mesa_data 
    stuff_mesa['L'    ] = (4 * pi * stuff_mesa['R1']**2 * (const.sigma_sb * stuff_mesa['T']**4)).to(units.Lsun)
    stuff_mesa['kappa'] = eos_opacity.get_kappa(rho=stuff_mesa['rho'], T=stuff_mesa['T'])
    stuff_mesa['dR1'] = -np.diff(stuff_mesa['R1'], append=0*units.Rsun)
    stuff_mesa['dtau'] = stuff_mesa['kappa'] * stuff_mesa['rho'] * stuff_mesa['dR1']
    stuff_mesa['tau'] = stuff_mesa['dtau'].cumsum()
    #stuff_mesa['wtf'  ] = (4 * pi * stuff_mesa['R1']**2 * (const.sigma_sb * stuff_mesa['T'].value**2.5 * units.K**4)).to(units.Lsun)
    # below should be one, but it is not. Not sure why
    L_0 = stuff_mesa['lum'][0]
    R_0 = stuff_mesa[ 'R1'][0]
    stuff_mesa['factor'] = (stuff_mesa['R1'].cgs**2 * (
        R_0**(-2) - integrate.cumulative_trapezoid(
            (stuff_mesa['kappa'] * stuff_mesa['rho'] / stuff_mesa['R1']**2).cgs, stuff_mesa['R1'].cgs, initial=0
        )*units.cm**(-2))).cgs
    stuff_mesa['wtf'  ]  = (integrate.cumulative_trapezoid(
            (stuff_mesa['kappa'] * stuff_mesa['rho'] / stuff_mesa['R1']**2)[::-1].cgs, stuff_mesa['R1'][::-1].cgs, initial=0
        )*units.cm**(-2))[::-1]
    stuff_mesa['test' ]  = (stuff_mesa['R1'].cgs[0]**2 * (
        stuff_mesa['R1'].cgs**(-2) - integrate.cumulative_trapezoid(
            (stuff_mesa['kappa'] * stuff_mesa['rho'] / stuff_mesa['R1']**2).cgs, stuff_mesa['R1'].cgs, initial=0
        )*units.cm**(-2))).cgs
    return stuff_mesa







use_Tscales = ''     #'', 'scale', 'cut', 'delete'
job_nickname= '2mdnrt0e2' #'t0e1'
# xlim = (1., 1e3)
xlim = (252, 268)


label=f'phantom- ' + (f'T{use_Tscales}' if use_Tscales else 'normal')
# read data
job_profile = JOB_PROFILES_DICT[job_nickname]
job_name    = job_profile['job_name']
params      = job_profile['params']
eos_opacity = EoS_MESA_opacity(params, settings)
# reading mesa data
stuff_mesa = read_mesa_data(eos_opacity)
# reading phantom data
mpdf = mpdf_read(job_name, 0, eos_opacity, reset_xyz_by='R1', use_Tscales=use_Tscales)
mpdf.calc_sdf_params(['R1'])
sdf  = mpdf.data['gas']
sdf['R1_bin'] = np.floor(sdf['R1']*10)/10
ray = mupl.get_rays(mpdf.data['sink'][['x', 'y', 'z']].iloc[0], np.array([0., 0., 1.]))
srcfuncs = mpdf.const['sigma_sb'] * sdf['T']**4 #/ (4 * pi)

stuff = {}
stuff['kappa'] = mpdf.get_val('kappa').cgs
stuff['R1'   ] = mpdf.get_val('R1').to(units.Rsun)
stuff['T'    ] = mpdf.get_val('T').to(units.K)
stuff['L'    ] = (4 * pi * stuff['R1']**2 * (const.sigma_sb * stuff['T']**4)).to(units.Lsun)
stuff['rho'  ] = mpdf.get_val('rho').cgs
stuff['tau'  ] = np.ones(len(sdf))*PHOTOSPHERE_TAU * units.dimensionless_unscaled

# rolling summary
sdf_grpby = sdf.groupby('R1_bin')
sdf_avg = sdf_grpby.mean()
sdf_std = sdf_grpby.std()
sdf_cnt = sdf_grpby.count()['iorig']
print("Number of bins with less than 8 data points: ", np.count_nonzero(sdf_cnt < 8))

# reconstruct photosphere
sdf_avg['dR1'] = np.diff(sdf_avg['R1'], prepend=0)
sdf_std['dR1'] = 0.
sdf_avg['dtau'] = sdf_avg['kappa'] * sdf_avg['rho'] * sdf_avg['dR1']
sdf_std['dtau'] = sdf_avg['dtau'] * np.sqrt((sdf_std['kappa'] / sdf_avg['kappa'])**2 + (sdf_std['rho'] / sdf_avg['rho'])**2)
sdf_avg['tau'] = sdf_avg['dtau'][::-1].cumsum()[::-1]
sdf_std['tau'] = np.sqrt((sdf_std['dtau']**2)[::-1].cumsum()[::-1])

# get photosphere loc
ph_inner_layers = np.where(sdf_avg['tau'] >= PHOTOSPHERE_TAU)[0]
if ph_inner_layers.size:
    ph_ind = ph_inner_layers[-1]
    ph_R1 = sdf_avg['R1'].iloc[ph_ind]
else:
    ph_ind = len(sdf_avg) - 1
    ph_R1 = sdf_avg['R1'].iloc[-1] + sdf_avg['dR1'].iloc[-1]

# cleaning up
sdf_valp = sdf_avg + sdf_std
sdf_valm = sdf_avg - sdf_std

plt.close('all')
for what in ['T', 'rho', 'kappa', 'tau']:
    fig, ax, mask = plot_stuff(
        stuff, 'R1', what, mpdf,
        {'plot_title_suffix' : job_nickname + " - phantom vs mesa"},
        xlim=xlim, label=label,
    )
    
    xs, ys = stuff_mesa['R1'], stuff_mesa[what]
    if isinstance(xs, units.Quantity): xs = xs.value
    if isinstance(ys, units.Quantity): ys = ys.value
    if xlim is None: mask = np.ones_like(xs, dtype=np.bool_)
    else: mask = np.logical_and(xlim[0]*0.99 < xs, xs < xlim[1]*1.01)
    unit = mpdf.get_val(what).unit if what != 'tau' else units.dimensionless_unscaled
    
    ax.semilogy(xs[mask], ys[mask], '-', label='mesa', linewidth=4, alpha=0.8)
    ys_sdf = set_as_quantity(sdf_avg[what], unit).cgs.value
    ax.semilogy(sdf_avg['R1'], ys_sdf, 'o--', label='phantom- aggregate', color='C2', linewidth=4, alpha=0.8)
    ax.fill_between(sdf_avg['R1'], set_as_quantity(sdf_valm[what], unit).cgs.value, set_as_quantity(sdf_valp[what], unit).cgs.value, color='C2', alpha=0.4)
    if   what=='T':     ax.set_ylim(2e3, 9e3)
    elif what=='rho':   ax.set_ylim(8e-10, 5e-9)
    elif what=='kappa': ax.set_ylim(5e-4, 8.0)
    
    ax.axvline(x=stuff_mesa['R1'][0].value, color='orange', linestyle='dashed')
    ax.axvline(x=ph_R1, color='grey', linestyle='dashed')
    if what in {'T'}:
        ax.text(ph_R1, ys_sdf[ph_ind]*1.1, f"${what}_{{ph}}$ = {ys_sdf[ph_ind]:.0f} {unit.cgs.to_string('latex_inline')}")
    ax.legend(loc='lower left')
    outfilename_noext = f"{output_dir}phantom-vs-mesa_{job_nickname}_{what}-R1"
    if use_Tscales: outfilename_noext += f".T{use_Tscales}"

    for ext in ['.png']:  # do NOT save to '.pdf' due to large amount of particles
        outfilename = f"{outfilename_noext}{ext}"
        fig.savefig(f"{outfilename}")
        print(f"Saved to {outfilename}")




















# plotting image

norm_image = mpl.colors.LogNorm(1e-12, 1e-2, clip=False)

rays_res = 256
no_xy = (rays_res, rays_res)
no_xy_txt = 'x'.join([f'{i}' for i in no_xy])
output_dir = f'../fig/20240222_LCGen/{no_xy_txt}/'

hollywood_mode: bool = False # True


if __name__ == '__main__':

    

    outfilenames_dict = {
        'rads' : {},
        'contr': {},
    }

    figs = []
    
    data = {}
    plt.close('all')

    job_profile = JOB_PROFILES_DICT[job_nickname]
    job_name    = job_profile['job_name']
    # file_indexes= job_profile['file_indexes']

    for file_index in [0]: #file_indexes: #[0, 1200, 4800, 8000, 17600]: #
        plt.close('all')
        data_full = mupl.hdf5_load(f"{interm_dir}{job_nickname}_{file_index:05d}.lcgen.{no_xy_txt}.hdf5")
        xyzs_list = list(data_full.keys()).copy() if xyzs_list is None else xyzs_list
        
        # initialize
        for d in outfilenames_dict.keys():
            if job_nickname not in outfilenames_dict[d].keys():
                outfilenames_dict[d][job_nickname] = {xyzs: [] for xyzs in xyzs_list}

        for xyzs in xyzs_list:
            data = data_full[xyzs]
            # calc flux
            # rads = data['rads'].to(unit_I)
            flux = (data['rads']*data['area_per_ray']*units.rad**2 / spec_dist**2).to(unitsOut['flux'])
            
            # reconstructing rays
            rays_u = np.zeros((data['rays'].shape[0], 2, 3)) * units.au
            rays_u[:, 0, :2] = data['rays']
            rays_u[:, 1, :2] = data['rays']
            rays_u[:, 1] += data['ray_unit_vec'] * units.au

            I_avg = (data['lum']/(4*pi*spec_dist**2)*np.mean(data['area_per_ray']/data['area_one'])).to(unitsOut['flux'])
            I_range = np.min((20., (flux.max()/I_avg).cgs.value,)) * I_avg.value # flux.max().to(unit_I).value #
            

            # plotting

            for fig in figs:
                fig.clear()
                plt.close(fig)
                del fig
            del figs
            figs = []
            
            i_tr = 3560 if job_nickname not in {'2m_2022', '4m', '4md'} else 3500
            xylim_u = 100*units.au if file_index < i_tr else 250*units.au

            # cmap = plt.get_cmap('hot') #; cmap.set_over('white')
            fig, _, outfilenames = plot_heat(
                no_xy, rays_u, flux,
                data_label=f"Flux $F$ (at {spec_dist.value:.0f} {spec_dist.unit.to_string('latex_inline')})",
                xyzs=xyzs, save_label=f"image",
                job_profile=job_profile, file_index=file_index, cmap='hot', notes=data,
                norm=norm_image,
                cbar_num_fmt=lambda x, pos: f"{x:.2e}",
                text_color='white',
                xylim=xylim_u.to_value(rays_u.unit) if hollywood_mode else None,
                output_dir=output_dir, out_exts=['png'], verbose=verbose_loop)
            outfilenames_dict['rads' ][job_nickname][xyzs].append(outfilenames[-1])
            figs.append(fig)

            
            fig, _, outfilenames = plot_heat(
                no_xy, rays_u, data['contr'], data_label="contribution fraction of the most contributed",
                xyzs=xyzs, save_label=f"contr",
                job_profile=job_profile, file_index=file_index, cmap='seismic', notes=data,
                ticks=10,
                norm=mpl.colors.Normalize(0., 100.),
                text_color='white',
                xylim=xylim_u.to_value(rays_u.unit) if hollywood_mode else None,
                output_dir=output_dir, out_exts=['png'], verbose=verbose_loop)
            outfilenames_dict['contr'][job_nickname][xyzs].append(outfilenames[-1])
            figs.append(fig)
            # del data, rays_u, rads, I_avg, I_range
        del data_full
        gc.collect()
