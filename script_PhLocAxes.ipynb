{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cda03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scripts for analyzing of phantom outputs.\\n\\nThis script writes hdf5 files for each dump (and one hdf5 file synthsizing all outputs)\\n    to plot photosphere size vs time or orbital separation.\\nIt does so by plotting photosphere intersection with traced rays originating from the primary star\\n    and shooting along the axes of the coordination frame.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Scripts for analyzing of phantom outputs.\n",
    "\n",
    "This script writes hdf5 files for each dump (and one hdf5 file synthsizing all outputs)\n",
    "    to plot photosphere size vs time or orbital separation.\n",
    "It does so by plotting photosphere intersection with traced rays originating from the primary star\n",
    "    and shooting along the axes of the coordination frame.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30fd6f",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d3ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "#import pandas\n",
    "from astropy import units\n",
    "from astropy import constants as const\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#from moviepy.editor import ImageSequenceClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d110bbc5-fb24-495d-b62a-33bf01b9a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.\n"
     ]
    }
   ],
   "source": [
    "# import modules listed in ./lib/\n",
    "\n",
    "import clmuphantomlib as mupl\n",
    "from clmuphantomlib import get_col_kernel_funcs\n",
    "from clmuphantomlib.io import json_load, json_dump, hdf5_load, hdf5_dump\n",
    "from clmuphantomlib.settings import DEFAULT_SETTINGS as settings\n",
    "from clmuphantomlib.log import error, warn, note, debug_info\n",
    "from clmuphantomlib.log import is_verbose, say\n",
    "from clmuphantomlib.units_util import set_as_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6adf1-b024-4f90-a2b2-d7bb5d154442",
   "metadata": {},
   "source": [
    "    ## import modules in arbitrary directory\n",
    "    \n",
    "    #import sys\n",
    "    \n",
    "    ## path to my python module lib directory\n",
    "    ## *** CHECK THIS! *** #\n",
    "    #SRC_LIB_PATH = sys.path[0] + '/lib'\n",
    "    \n",
    "    #if SRC_LIB_PATH not in sys.path:\n",
    "    #    sys.path.append(SRC_LIB_PATH)\n",
    "    ##print(*sys.path, sep='\\n')    # debug\n",
    "    #print(\n",
    "    #    \"\\n*   Please Make sure my module files are located in this directory (or change the SRC_LIB_PATH variable):\",\n",
    "    #    f\"\\n{SRC_LIB_PATH = }\\n\"\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517d7e50-25fe-4750-8c5b-3e94519c1842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parallels & optimizations\n",
    "\n",
    "\n",
    "#import os\n",
    "## Fixing stupid numba killing kernel\n",
    "## See here https://github.com/numba/numba/issues/3016\n",
    "#os.environ['NUMBA_DISABLE_INTEL_SVML']  = '1'\n",
    "#from numba import njit, prange\n",
    "\n",
    "\n",
    "from multiprocessing import cpu_count, Pool #Process, Queue\n",
    "NPROCESSES = 1 if cpu_count() is None else max(cpu_count(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37d5dde-8b39-4409-9bec-8ae2cabba7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Note   :    script:\n",
      "\tWill use 8 processes for parallelization\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "#\n",
    "#   imported from script_input.py file\n",
    "\n",
    "from script_PhLocAxes__input import interm_dir, verbose, PHOTOSPHERE_TAU, JOB_PROFILES\n",
    "from _sharedFuncs import mpdf_read\n",
    "\n",
    "\n",
    "# set metadata\n",
    "with open(\"_metadata__input.json\", 'r') as f:\n",
    "    metadata = mupl.json_load(f)\n",
    "metadata['Title'] = \"Getting photosphere size on x, y, z axes\"\n",
    "metadata['Description'] = f\"\"\"Tracing 6 rays on +x, -x, +y, -y, +z, -z directon and get photosphere size, h, rho, u, T from them.\"\"\"\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "\n",
    "# print debug info\n",
    "if __name__ == '__main__' and is_verbose(verbose, 'note'):\n",
    "    # remember to check if name is '__main__' if you wanna say anything\n",
    "    #    so when you do multiprocessing the program doesn't freak out\n",
    "    say('note', \"script\", verbose, f\"Will use {NPROCESSES} processes for parallelization\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae56404-ba6d-422e-929c-84537ad1f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import (my libs)\n",
    "from clmuphantomlib.log import say, is_verbose\n",
    "from clmuphantomlib.geometry import get_dist2_between_2pt, get_closest_pt_on_line, get_dist2_from_pt_to_line_nb, get_ray_unit_vec, get_rays_unit_vec\n",
    "from clmuphantomlib.sph_interp import get_sph_interp, get_h_from_rho, get_no_neigh\n",
    "from clmuphantomlib.units_util import set_as_quantity, set_as_quantity_temperature, get_units_field_name\n",
    "from clmuphantomlib.eos.base import EoS_Base\n",
    "#  import (general)\n",
    "import numpy as np\n",
    "from numpy import typing as npt\n",
    "import numba\n",
    "from numba import jit, prange\n",
    "import sarracen\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63b52a2-8cf5-47d4-94c8-b424f911c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photosphere_on_ray(\n",
    "    pts_on_ray            : np.ndarray,\n",
    "    dtaus                 : np.ndarray,\n",
    "    pts_order             : np.ndarray,\n",
    "    sdf                   : sarracen.SarracenDataFrame,\n",
    "    ray                   : np.ndarray,\n",
    "    calc_params           : list       = ['loc', 'R1'],\n",
    "    hfact                 : float      = None,\n",
    "    mpart                 : float      = None,\n",
    "    eos                   : EoS_Base   = None,\n",
    "    sdf_units             : dict       = None,\n",
    "    ray_unit_vec          : np.ndarray = None,\n",
    "    kernel                : sarracen.kernels.base_kernel = None,\n",
    "    do_skip_zero_dtau_pts : bool       = True,\n",
    "    do_use_precise_calc   : bool       = True,\n",
    "    photosphere_tau       : float      = 1.,\n",
    "    waypts_max_tau        : None|float = 1e3,\n",
    "    waypts_nsample        : int        = 4096,\n",
    "    ndim                  : int        = 3,\n",
    "    return_as_quantity    : bool|None  = True,\n",
    "    verbose : int = 3,\n",
    ") -> tuple[dict, tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Calc the location where the photosphere intersect with the ray.\n",
    "\n",
    "    Assuming 3D.\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pts_on_ray, dtaus, pts_order\n",
    "        output from get_optical_depth().\n",
    "\n",
    "        pts_on_ray: np.ndarray\n",
    "            Orthogonal projections of the particles' locations onto the ray.\n",
    "        \n",
    "        dtaus: np.ndarray\n",
    "            Optical depth tau contributed by each particles. In order of the original particles order in the dump file.\n",
    "            Remember tau is a dimensionless quantity.\n",
    "        \n",
    "        pts_order: np.ndarray\n",
    "            indices of the particles where dtaus are non-zero.\n",
    "            The indices are arranged by distances to the observer, i.e. the particles closest to the observer comes first, \n",
    "            and the furtherest comes last.\n",
    "\n",
    "    sdf: sarracen.SarracenDataFrame\n",
    "        Must contain columns: x, y, z, h    # kappa, rho,\n",
    "        \n",
    "    ray: (2, 3)-shaped numpy array, i.e. [pt1, pt2]\n",
    "        2 points required to determine a line.\n",
    "        The line is described as X(t) = pt1 + t*(pt2-pt1)\n",
    "        First  point pt1 is the reference of the distance if R1 is calc-ed.\n",
    "        Second point pt2 points to the observer, and is closer to the observer.\n",
    "\n",
    "    calc_params: list or tuple of str\n",
    "        parameters to be calculated / interpolated at the photosphere location.\n",
    "        Results will be put into the photosphere dict in the output.\n",
    "        Acceptable input: (Note: will always calc 'loc' if calc_params is not empty)\n",
    "            'is_found': will return bool.\n",
    "                Will always be outputted regardless of in calc_params or not.\n",
    "            'loc': will return (3,)-shaped numpy array.\n",
    "                photophere location.\n",
    "            'R1' : will return float.\n",
    "                distance between photosphere location and the ray[0].\n",
    "                Could be negative if loc is on the other side of the ray.\n",
    "            'nneigh': will return int.\n",
    "                Number of neighbour particles of the photosphere loc.\n",
    "            'rho': will return float.\n",
    "                density at the photosphere.\n",
    "            'u': will return float.\n",
    "                specific internel energy at the photosphere.\n",
    "            'h'  : will return float.\n",
    "                smoothing length at the photosphere.\n",
    "                Will always calc 'rho' if to calc 'h'.\n",
    "            'T'  : will return float.\n",
    "                Temperature at the photosphere.\n",
    "                Warning: if not supplied 'temp' keyword in sdf_units, will return in cgs units.\n",
    "    \n",
    "    hfact, mpart: float\n",
    "        Only useful if you are calc-ing 'h'\n",
    "        $h_\\\\mathrm{fact}$ and particle mass used in the phantom sim.\n",
    "        If None, will get from sdf.params['hfact'] and sdf.params['mass']\n",
    "\n",
    "    eos: .eos.base.EoS_BASE\n",
    "        Only useful if you are calc-ing 'T'\n",
    "        Equation of state object defined in eos/base.py\n",
    "\n",
    "    sdf_units: dict\n",
    "        Only useful if you are calc-ing 'T'\n",
    "        in which case, supply rho, u, and T units in this dict\n",
    "        e.g.\n",
    "        sdf_units = {\n",
    "            'density': units.Msun / units.Rsun**3,\n",
    "            'specificEnergy': units.Rsun**2 / units.s**2,\n",
    "            'temp': units.K,\n",
    "        }\n",
    "    \n",
    "    ray_unit_vec: (3,)-shaped np.ndarray\n",
    "        unit vector of ray. will calc this if not supplied.\n",
    "        \n",
    "    kernel: sarracen.kernels.base_kernel\n",
    "        Smoothing kernel for SPH data interpolation.\n",
    "        If None, will use the one in sdf.\n",
    "        \n",
    "    do_skip_zero_dtau_pts: bool\n",
    "        Whether or not to skip particles with zero dtaus (i.e. no contribution to opacity) to save computational time.\n",
    "        If skiped, these particles' locs will be excluded from results as well\n",
    "\n",
    "    do_use_precise_calc: bool\n",
    "        If True, will use the new tau interpolation algorithm used in LCGen.\n",
    "        otherwise, will just interpolate from dtaus input (i.e. assuming each SPH particle is a point mass)\n",
    "        \n",
    "    photosphere_tau: float\n",
    "        At what optical depth (tau) is the photosphere defined.\n",
    "\n",
    "    waypts_max_tau: float\n",
    "        maximum optical depth that we will look inside.\n",
    "\n",
    "    return_as_quantity: bool | None\n",
    "        If True or None, the results in photosphere will be returned as a astropy.units.Quantity according to sdf_units.\n",
    "        (pts_waypts, pts_waypts_t, taus_waypts) will also be returned as numpy array and NOT as Quantity.\n",
    "        The diff between True and None is that True will raise an error if units not supplied in sdf_units,\n",
    "        while None will just return as numpy array in such case.\n",
    "        \n",
    "    \n",
    "    verbose: int\n",
    "        How much warnings, notes, and debug info to be print on screen. \n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    photosphere, (pts_waypts, pts_waypts_t, taus_waypts)\n",
    "\n",
    "    photosphere: dict\n",
    "        dict of values found at the photosphere intersection point with the ray.\n",
    "        will always have \n",
    "\n",
    "    pts_waypts: (npart, 3)-shaped numpy array\n",
    "        location of the waypoints on ray\n",
    "\n",
    "    pts_waypts_t: (npart)-shaped numpy array\n",
    "        distance of the waypoints from ray[0]\n",
    "\n",
    "    taus_waypts: (npart)-shaped numpy array\n",
    "        optical depth at the waypoints.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # init\n",
    "    ray = np.array(ray)\n",
    "    if ray_unit_vec is None:\n",
    "        ray_unit_vec = get_ray_unit_vec(ray)\n",
    "    if kernel is None:\n",
    "        kernel = sdf.kernel\n",
    "    kernel_col, kernel_csz, _, _ = get_col_kernel_funcs(kernel)\n",
    "    if do_skip_zero_dtau_pts:\n",
    "        pts_order = pts_order[np.where(dtaus[pts_order])]\n",
    "    ray_0 = np.asarray(ray[0])\n",
    "    pts_ordered    = np.asarray(sdf[['x', 'y', 'z']].iloc[pts_order])\n",
    "    hs_ordered     = np.asarray(sdf[ 'h'           ].iloc[pts_order])\n",
    "    #kappas_ordered = np.array(sdf[ 'kappa'       ].iloc[pts_order])\n",
    "    #rhos_ordered   = np.array(sdf[ 'rho'         ].iloc[pts_order])\n",
    "    pts_on_ray_ordered = pts_on_ray[pts_order]\n",
    "    npart_ordered = pts_ordered.shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "    # get waypts (way points) for pts (point locations) and taus (optical depths)\n",
    "    #  waypts are suitable for linear interpolation\n",
    "    #  taus_waypts[0] is 0; taus_waypts[-1] is total optical depth from the object\n",
    "\n",
    "    \n",
    "    #  step 1: determine the waypts location by assuming pts as balls with constant kappa and density\n",
    "    \n",
    "    #   step 1a: getting the size of pts balls on the ray\n",
    "    pts_dist2_to_ray = get_dist2_between_2pt(pts_ordered, pts_on_ray_ordered)\n",
    "    #    Assuming a h radius ball\n",
    "    pts_radius = kernel.get_radius() * hs_ordered\n",
    "    pts_size_on_ray = pts_radius**2 - pts_dist2_to_ray\n",
    "    # put a small number (1e-8*h) in case of negative pts_size_on_ray, so that the code does not freak out\n",
    "    pts_size_on_ray_min = 1e-8*hs_ordered\n",
    "    pts_size_on_ray = np.where(pts_size_on_ray < pts_size_on_ray_min**2, pts_size_on_ray_min, pts_size_on_ray**0.5)\n",
    "    #pts_size_on_ray = dtaus_ordered / (kappas_ordered * rhos_ordered)    # does not work because rho is not a constant within the particle\n",
    "\n",
    "    #   step 1b: getting the waypoint locs\n",
    "    pts_on_ray_t_ordered = np.sum((pts_on_ray_ordered - ray_0) * ray_unit_vec, axis=-1)\n",
    "    if waypts_max_tau is None:\n",
    "        # calc waypoints by interpolating ALL relavent particle's positions\n",
    "        #    pts_waypts_t: the distance from waypts to ray_0 (negative if in the opposite direction)\n",
    "        pts_waypts_t = np.interp(    # 5 data points in between pts, so npart_ordered*5 - 1\n",
    "            np.linspace(0, npart_ordered-1, (npart_ordered-1)*5 + 1),\n",
    "            np.linspace(0, npart_ordered-1, npart_ordered),\n",
    "            pts_on_ray_t_ordered)\n",
    "        pts_waypts_t = np.concatenate((    # add before and after the first particles\n",
    "            np.linspace(pts_on_ray_t_ordered[0] + pts_radius[0], pts_on_ray_t_ordered[0], 10),\n",
    "            pts_waypts_t,\n",
    "            np.linspace(pts_on_ray_t_ordered[-1] - pts_radius[-1], pts_on_ray_t_ordered[-1], 10),\n",
    "        ))\n",
    "    else:\n",
    "        # calc waypoints by interpolating between tau = 0 and tau = waypts_max_tau\n",
    "        ind = max(np.searchsorted(np.cumsum(dtaus), waypts_max_tau), npart_ordered-1)\n",
    "        pts_waypts_t = np.linspace(\n",
    "            pts_on_ray_t_ordered[0  ] + pts_radius[0  ],\n",
    "            pts_on_ray_t_ordered[ind] - pts_radius[ind],\n",
    "            waypts_nsample+1, endpoint=False)[1:]    # remove head point to avoid division by zero warnings\n",
    "    pts_waypts = ray_0 + pts_waypts_t[:, np.newaxis] * ray_unit_vec[np.newaxis, :]\n",
    "        \n",
    "\n",
    "    #   step 1c: sort waypoint locs\n",
    "    #    sorting should not be necessary, but just in case\n",
    "    pts_waypts_inds = np.argsort(pts_waypts_t)[::-1]\n",
    "    pts_waypts   = pts_waypts[  pts_waypts_inds]\n",
    "    pts_waypts_t = pts_waypts_t[pts_waypts_inds]\n",
    "    \n",
    "    #  step 2: determine the waypts optical depth\n",
    "    taus_waypts = np.zeros(pts_waypts.shape[0])\n",
    "    if do_use_precise_calc:\n",
    "        # re-calc\n",
    "        mkappa_div_h2_ordered = np.asarray(sdf['m'].iloc[pts_order] * sdf['kappa'].iloc[pts_order] / hs_ordered**2)\n",
    "        for j in range(npart_ordered):\n",
    "            h = hs_ordered[j]\n",
    "            q_xy_j = pts_dist2_to_ray[j]**0.5 / h\n",
    "            t_j = pts_on_ray_t_ordered[j]\n",
    "            taus_waypts += mkappa_div_h2_ordered[j] * np.asarray([\n",
    "                kernel_csz(q_xy_j, -(t_k - t_j)/h, ndim) for t_k in pts_waypts_t])\n",
    "    else:\n",
    "        # interpolate from given dtau (not the same as in LCGen)\n",
    "        for waypt_t, h, dtau in zip(pts_waypts_t, hs_ordered, dtaus[pts_order]):\n",
    "            hr = h * kernel.get_radius()\n",
    "            # Note: np.interp assumes xp increasing, so we need to reverse this\n",
    "            taus_waypts += np.interp(pts_waypts_t[::-1], [waypt_t-hr, waypt_t+hr], [dtau, 0.], left=dtau, right=0.)[::-1]\n",
    "        \n",
    "\n",
    "    # prepare answers\n",
    "    # is found?\n",
    "    if not taus_waypts.size:\n",
    "        taus_max = 0\n",
    "    elif np.isfinite(taus_waypts[-1]):\n",
    "        # in case there is nan in the later part of the array\n",
    "        taus_max = taus_waypts[-1]\n",
    "    else:\n",
    "        taus_max = np.nanmax(taus_waypts)\n",
    "    photosphere = {\n",
    "        'is_found': (taus_max > photosphere_tau)\n",
    "    }\n",
    "    \n",
    "    # get photosphere parameters\n",
    "    if calc_params:\n",
    "        # always calc location if anything needs to be calc-ed\n",
    "        photosphere['loc'] = np.array([\n",
    "            np.interp(photosphere_tau, taus_waypts, pts_waypts[:, ax], right=np.nan) if taus_waypts.size else np.nan\n",
    "            for ax in range(pts_waypts.shape[1])\n",
    "        ])\n",
    "\n",
    "        # do prerequisite check\n",
    "        calc_params = list(calc_params)\n",
    "        if 'h' in calc_params:\n",
    "            if 'rho' not in calc_params: calc_params.append('rho')\n",
    "        if 'T'   in calc_params:\n",
    "            if 'rho' not in calc_params: calc_params.append('rho')\n",
    "            if 'u'   not in calc_params: calc_params.append('u')\n",
    "\n",
    "        # first calc prerequisites\n",
    "        calc_these = []\n",
    "        for calc_name in calc_params:\n",
    "            if   calc_name == 'loc':\n",
    "                # already calc-ed\n",
    "                pass\n",
    "            elif calc_name == 'R1':\n",
    "                photosphere['R1']  = np.interp(photosphere_tau, taus_waypts, pts_waypts_t, right=np.nan) if taus_waypts.size else np.nan\n",
    "            elif calc_name in {'rho', 'u'}:\n",
    "                photosphere[calc_name]  = get_sph_interp(sdf, calc_name, photosphere['loc'], kernel=kernel, verbose=verbose)\n",
    "            elif calc_name in {'nneigh'}:\n",
    "                photosphere[calc_name]  = get_no_neigh(sdf, photosphere['loc'], kernel=kernel, verbose=verbose)\n",
    "            else:\n",
    "                calc_these.append(calc_name)\n",
    "    \n",
    "        # now the rest\n",
    "        for calc_name in calc_these:\n",
    "            if calc_name == 'h':\n",
    "                if hfact is None: hfact = sdf.params['hfact']\n",
    "                if mpart is None: mpart = sdf.params['mass']\n",
    "                photosphere['h']  = get_h_from_rho(photosphere['rho'], mpart, hfact)\n",
    "            elif calc_name == 'T':\n",
    "                if eos   is None: raise ValueError(\"get_photosphere_on_ray(): Please supply equation of state to calculate temperature.\")\n",
    "                try:\n",
    "                    photosphere['T']  = eos.get_temp(\n",
    "                        set_as_quantity(photosphere['rho'], sdf_units['density']),\n",
    "                        set_as_quantity(photosphere['u'  ], sdf_units['specificEnergy']))\n",
    "                    if 'temp' in sdf_units:\n",
    "                        photosphere['T'] = set_as_quantity_temperature(photosphere['T'], sdf_units['temp']).value\n",
    "                    else:\n",
    "                        photosphere['T'] = photosphere['T'].value\n",
    "                except ValueError:\n",
    "                    # eos interp could go out of bounds if it's a tabulated EoS\n",
    "                    # which will raise a Value Error\n",
    "                    photosphere['T'] = np.nan\n",
    "            else:\n",
    "                # just interpolate it (#IT-JUST-WORKS)\n",
    "                photosphere[calc_name]  = get_sph_interp(sdf, calc_name, photosphere['loc'], kernel=kernel, verbose=verbose)\n",
    "\n",
    "        # add units\n",
    "        if return_as_quantity or return_as_quantity is None:\n",
    "            for calc_name in photosphere.keys():\n",
    "                if calc_name not in {'is_found', 'nneigh'}:\n",
    "                    # find appropriate unit\n",
    "                    try:\n",
    "                        unit_field_name = get_units_field_name(calc_name)\n",
    "                    except NotImplementedError:\n",
    "                        # failed to find unit type\n",
    "                        unit_field_name = None\n",
    "                    if unit_field_name in sdf_units.keys():\n",
    "                        # add units\n",
    "                        photosphere[calc_name] = set_as_quantity(photosphere[calc_name], sdf_units[unit_field_name])\n",
    "                    # errors\n",
    "                    elif unit_field_name is None:\n",
    "                        if is_verbose(verbose, 'warn'):\n",
    "                            say('warn', 'get_photosphere_on_ray()', verbose,\n",
    "                                f\"Cannot find the corresponding unit for {calc_name}. Will return as numpy array instead.\")\n",
    "                    elif return_as_quantity is not None:\n",
    "                        raise ValueError(f\"Please supply {unit_field_name} in sdf_units.\")\n",
    "        \n",
    "        \n",
    "    return photosphere, (pts_waypts, pts_waypts_t, taus_waypts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40466d2f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f063ed6",
   "metadata": {},
   "source": [
    "## Photosphere size vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8132b3-209d-4680-b364-d9d5eb4cb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ph_loc_axes(\n",
    "    job_profile : dict,\n",
    "    #job_name : str,\n",
    "    file_indexes : np.ndarray,\n",
    "    rays_dir_def : dict,    # dict of list\n",
    "    eoses : (mupl.eos.base.EoS_Base, mupl.eos.mesa.EoS_MESA_opacity),\n",
    "    photosphere_tau = PHOTOSPHERE_TAU,\n",
    "    verbose : int = 2,\n",
    "    interp_method: str = 'basic',    # 'basic' or 'improved'\n",
    "):\n",
    "\n",
    "    \"\"\"Writing the photosphere locations of each dump to json files.\n",
    "\n",
    "    Notes:\n",
    "    Using mpdf.params['hfact']\n",
    "    \"\"\"\n",
    "    # will calc some of it regardless of whether they are included in calc_params\n",
    "    calc_params = ['loc', 'R1', 'rho', 'u', 'h', 'T', 'kappa', 'kappaDust', 'srcfunc', 'Skapparho']\n",
    "\n",
    "    \n",
    "    #mpdf = mupl.MyPhantomDataFrames()\n",
    "\n",
    "    \n",
    "    job_name = job_profile['job_name']\n",
    "    #X = job_profile['X']\n",
    "    #ieos = job_profile['ieos']\n",
    "\n",
    "    eos, eos_opacity = eoses\n",
    "\n",
    "    \n",
    "    # init rays directions\n",
    "    rays_dir = {}\n",
    "    for key in rays_dir_def.keys():\n",
    "        rays_dir[key] = np.array(rays_dir_def[key])\n",
    "\n",
    "\n",
    "    # main\n",
    "    for file_index in file_indexes:\n",
    "        \n",
    "        # init answer dict / array\n",
    "        photosphere_pars = { # [legend][par_name][time]\n",
    "            'time_yr': None,\n",
    "            'orbsep_Rsun': None,\n",
    "            'mpart_Msun' : None,\n",
    "            'data': {},\n",
    "            'rays_dir': rays_dir_def,\n",
    "            'rays': {},\n",
    "        }  \n",
    "        for key in rays_dir.keys():\n",
    "            photosphere_pars['data'][key] = {}\n",
    "\n",
    "        # read data\n",
    "        mpdf = mpdf_read(job_name, file_index, eos_opacity, mpdf=None, reset_xyz_by='CoM', do_extrap=False, verbose=verbose)\n",
    "        sdf = mpdf.data['gas']\n",
    "        sdf['srcfunc'] = mpdf.const['sigma_sb'] * sdf['T']**4 / pi\n",
    "        sdf['Skapparho'] = sdf['srcfunc'] * sdf['kappa'] * sdf['rho']\n",
    "        \n",
    "        #mpdf.read(job_name, file_index, reset_xyz_by='CoM', verbose=verbose)\n",
    "        #if 'Tdust' in mpdf.data['gas'].columns:\n",
    "        #    mpdf.data['gas']['T'] = mpdf.data['gas']['Tdust']\n",
    "        #elif 'temperature' in mpdf.data['gas'].columns:\n",
    "        #    mpdf.data['gas']['T'] = mpdf.data['gas']['temperature']\n",
    "        #if 'kappa' not in mpdf.data['gas'].keys():\n",
    "        #    # get kappa from mesa table in cgs units\n",
    "        #    mpdf.data['gas']['kappa'] = eos_opacity.get_kappa(\n",
    "        #        mpdf.get_val('rho', copy=False),\n",
    "        #        mpdf.get_val('T', copy=False),\n",
    "        #        do_extrap=True,\n",
    "        #        return_as_quantity=False)\n",
    "        ## translate to phantom units\n",
    "        #mpdf.calc_sdf_params(\n",
    "        #    calc_params=['kappa',], #'R1',\n",
    "        #    calc_params_params={'ieos': ieos, 'X':X, 'overwrite':False, 'kappa_translate_from_cgs_units':True},\n",
    "        #    verbose=verbose,\n",
    "        #)\n",
    "        hfact = mpdf.params['hfact']\n",
    "        mpart = mpdf.params['mass']\n",
    "        \n",
    "        photosphere_pars['time_yr'] = mpdf.get_time().to_value(units.year)\n",
    "        photosphere_pars['orbsep_Rsun'] = mpdf.get_orb_sep().to_value(units.Rsun)\n",
    "        photosphere_pars['mpart_Msun']  = (mpart * mpdf.units['mass']).to_value(units.Msun)\n",
    "\n",
    "\n",
    "        ## construct kdtree (since we are not changing x, y, z label here)\n",
    "        #sdf_all_kdtree = kdtree.KDTree(np.array(sdf[['x', 'y', 'z']], copy=False))\n",
    "\n",
    "        # construct rays_dict\n",
    "        star_loc = np.array([mpdf.data['sink'][axis][0] for axis in 'xyz'])\n",
    "        rays_dict = {}    # legend: ray\n",
    "        for key in rays_dir.keys():\n",
    "            # init\n",
    "            ray = np.array([\n",
    "                star_loc,\n",
    "                star_loc + rays_dir[key],\n",
    "            ])\n",
    "            rays_dict[key] = ray\n",
    "            photosphere_pars['rays'][key] = ray.tolist()\n",
    "            ray_unit_vec = ray[1, :] - ray[0, :]\n",
    "            ray_unit_vec = ray_unit_vec / np.sum(ray_unit_vec**2)**0.5\n",
    "\n",
    "\n",
    "            # optimization- first select only the particles affecting the ray\n",
    "            #  because interpolation of m points with N particles scales with O(N*m),\n",
    "            #  reducing N can speed up calc significantly\n",
    "            sdf = mpdf.data['gas']\n",
    "            kernel_radius = sdf.kernel.get_radius()\n",
    "            hs = np.array(sdf['h'])\n",
    "            pts = np.array(sdf[['x', 'y', 'z']])    # (npart, 3)-shaped array\n",
    "            pts_on_ray = mupl.get_closest_pt_on_line(pts, ray)\n",
    "            sdf_selected_indices = (np.sum((pts - pts_on_ray)**2, axis=-1) <= (kernel_radius * hs)**2)\n",
    "            if verbose:\n",
    "                debug_info(\n",
    "                    'write_ph_loc_axes()', verbose,\n",
    "                    f\"{np.count_nonzero(sdf_selected_indices)} particles are close enough to the ray to have effects.\"\n",
    "                )\n",
    "            sdf = sdf.iloc[sdf_selected_indices]\n",
    "            pts = np.array(sdf[['x', 'y', 'z']])    # (npart, 3)-shaped array\n",
    "\n",
    "\n",
    "            # get optical depth\n",
    "            if verbose:\n",
    "                debug_info(\n",
    "                    'write_ph_loc_axes()', verbose,\n",
    "                    f\"{ray = }\"\n",
    "                )\n",
    "            pts_on_ray, dtaus, pts_order = mupl.light.get_optical_depth_by_ray_tracing_3D(sdf=sdf, ray=ray)\n",
    "            photosphere, (pts_waypts, pts_waypts_t, taus_waypts) = get_photosphere_on_ray(\n",
    "                pts_on_ray, dtaus, pts_order, sdf, ray,    # remove dtaus to force recalc in LCGen way\n",
    "                calc_params = calc_params,\n",
    "                hfact = hfact, mpart=mpart, eos=eos, sdf_units=mpdf.units,\n",
    "                ray_unit_vec=ray_unit_vec, verbose=verbose, photosphere_tau=photosphere_tau,\n",
    "                return_as_quantity=False,\n",
    "            )\n",
    "\n",
    "            if is_verbose(verbose, 'debug'):\n",
    "                say('debug', None, verbose,\n",
    "                    f\"{photosphere = }\\n\",\n",
    "                    f\"{len(taus_waypts) = }\\n\",\n",
    "                )\n",
    "            \n",
    "            photosphere_pars['data'][key] = photosphere\n",
    "            photosphere_pars['data'][key]['size'] = photosphere['R1']\n",
    "            ph_d = photosphere_pars['data'][key]\n",
    "\n",
    "            # save interpolated data on ray at waypoints\n",
    "            ph_d[ 'R1_on_ray'] = pts_waypts_t\n",
    "            ph_d['loc_on_ray'] = ray[0][np.newaxis, :] + ph_d['R1_on_ray'][:, np.newaxis] * ray_unit_vec[np.newaxis, :]\n",
    "            ph_d['tau_on_ray'] = np.interp(ph_d['R1_on_ray'], pts_waypts_t[::-1], taus_waypts[::-1])\n",
    "            ph_d['rho_on_ray'] = mupl.sph_interp.get_sph_interp(sdf, 'rho', ph_d['loc_on_ray'], verbose=verbose, method=interp_method)\n",
    "            ph_d[  'h_on_ray'] = mupl.sph_interp.get_h_from_rho(ph_d['rho_on_ray'], mpart=mpart, hfact=hfact)\n",
    "            ph_d[  'u_on_ray'] = mupl.sph_interp.get_sph_interp(\n",
    "                sdf, 'u'  , ph_d['loc_on_ray'], verbose=verbose, method=interp_method)\n",
    "            ph_d[  'T_on_ray'] = eos.get_temp(\n",
    "                set_as_quantity(photosphere_pars['data'][key]['rho_on_ray'], mpdf.units['density']),\n",
    "                set_as_quantity(photosphere_pars['data'][key]['u_on_ray']  , mpdf.units['specificEnergy']),\n",
    "                return_as_quantity=False, bounds_error=False)\n",
    "            for par in calc_params:\n",
    "                if par in {'R1', 'loc', 'tau', 'rho', 'h', 'u', 'T'}:\n",
    "                    continue    # already handled\n",
    "                elif par in sdf:    # just interpolate it    #IT-JUST-WORKS\n",
    "                    ph_d[f'{par}_on_ray'] = mupl.sph_interp.get_sph_interp(\n",
    "                        sdf, par, ph_d['loc_on_ray'], verbose=verbose, method=interp_method)\n",
    "                else:\n",
    "                    say('warn', None, verbose, f\"{par} not found in data dump '{job_name}_{file_index:05}'.\")\n",
    "            # photosphere_pars['data'][key]['nneigh_on_ray']=mupl.sph_interp.get_no_neigh(\n",
    "            #     sdf, ph_d['loc_on_ray'], hs_at_locs=ph_d['h_on_ray'], kernel_rad=kernel_radius)\n",
    "\n",
    "            # save actual relevant particle data (pts)\n",
    "            #    Rt_pts: equivalant of R1_on_ray but for particles\n",
    "            ph_d[ 'Rt_at_pts'] = np.sum((pts_on_ray[pts_order] - np.asarray(ray[0])) * ray_unit_vec, axis=-1)\n",
    "            ph_d['Rxy_at_pts'] = get_dist2_between_2pt(pts[pts_order], pts_on_ray[pts_order])**0.5\n",
    "            ph_d['tau_at_pts'] = np.cumsum(dtaus[pts_order])\n",
    "            for par in calc_params:\n",
    "                if par in {'R1', 'loc', 'tau',}:\n",
    "                    continue\n",
    "                elif par in sdf:\n",
    "                    ph_d[f'{par}_at_pts'] = np.asarray(sdf[par].iloc[pts_order])\n",
    "                else:\n",
    "                    say('warn', None, verbose, f\"{par} not found in data dump '{job_name}_{file_index:05}'.\")\n",
    "\n",
    "\n",
    "        hdf5_dump(\n",
    "            photosphere_pars,\n",
    "            f\"{interm_dir}{job_profile['nickname']}_{file_index:05d}.photospherePars.xyz.hdf5\",\n",
    "            metadata=metadata)\n",
    "        del mpdf\n",
    "\n",
    "    return photosphere_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a0ce8-57ed-4eeb-b09b-218f80982760",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe765991-3271-4c30-a63e-18628d8e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_debug = True\n",
    "if do_debug and __name__ == '__main__':\n",
    "    from script_PhLocAxes__input import JOB_PROFILES_DICT\n",
    "    JOB_PROFILES = [JOB_PROFILES_DICT[key] for key in ('2md',)] #('2md', '4md')]\n",
    "    for job_profile in JOB_PROFILES:\n",
    "        job_profile['file_indexes'] = (0, 100) #(0, 400, 1200, 1600, 2000, 4800, 15600, 17600)\n",
    "    NPROCESSES = 1\n",
    "    verbose=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951dd520-ce47-42ce-9b21-f4f1951e1cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Note   :    write_ph_loc_axes() ==> mpdf_read() ==> read():\n",
      "\t\n",
      "\n",
      "\tReading filename='../raw/luis_2md/light_00000'\n",
      "\n",
      "\n",
      "    Debug  :    write_ph_loc_axes() ==> mpdf_read() ==> read():\n",
      "\tudist = 1.00036 solRad\n",
      "\tumass = 1.00035 solMass\n",
      "\tutime = 1.00053 unit_time\n",
      "\tself.time = np.float64(0.0)\n",
      "self.gamma = np.float64(1.6666666666666667)\n",
      "self.ieos = 10\n",
      "self.total_mass = np.float64(2.3056731566759385)\n",
      "\n",
      "\tCenter of mass location: self.loc_CoM = array([9.36841334e-13, 3.02453466e-14, 2.47169186e-14])\n",
      "\n",
      "*   Note   :    mpdf_read() ==> read() ==> reset_xyz_by():\n",
      "\tReseting Origin to CoM ([9.36841334e-13 3.02453466e-14 2.47169186e-14])...\n",
      "*   Note   :    mpdf_read() ==> read() ==> reset_xyz_by():\n",
      "\tCoM location is now [ 0.00000000e+00  3.59257537e-16 -1.80945419e-16]\n",
      "**  Warning:    write_ph_loc_axes() ==> mpdf_read() ==> read():\n",
      "\tkappa column exists.\n",
      "\tWe here assume kappa is in phantom units self.units['opacity']=Unit(\"udist2 / umass\") \n",
      "\tHowever in phantom kappa is assumed to be in cgs unit.\n",
      "\tIf so, please CONVERT KAPPA MANNUALLY into PHANTOM units BEFORE proceeding, e.g.:\n",
      "\t\tmpdf.data['gas']['kappa'] = mupl.units_util.get_val_in_unit(\n",
      "\t\tmpdf.data['gas']['kappa'], units.cm**2/units.g, mpdf.units['opacity'])\n",
      "    Debug  :    <module>() ==> write_ph_loc_axes() ==> mpdf_read():\n",
      "\tnp.count_nonzero(mpdf.data['gas']['kappaDust']) = 0\n",
      "\tnp.count_nonzero(mpdf.data['gas']['kappa'])      = 1372088\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4358 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-1.43135206e+02,  6.48807731e-03,  5.43625638e-03],\n",
      "       [-1.42135206e+02,  6.48807731e-03,  5.43625638e-03]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([2.86089688e+02, 6.48807731e-03, 5.43625638e-03]), 'R1': np.float64(429.2248934392569), 'rho': array(8.49409201e-12), 'u': array(0.00144071), 'h': np.float64(55.31875466740644), 'T': np.float64(6401.838045648185), 'kappa': array(2.39801036e+10), 'kappaDust': array(0.), 'srcfunc': array(5.67400172e-14), 'Skapparho': array(2.08177446e-14)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4375 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-1.43135206e+02,  6.48807731e-03,  5.43625638e-03],\n",
      "       [-1.43135206e+02,  1.00648808e+00,  5.43625638e-03]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-1.43135206e+02,  4.20839252e+02,  5.43625638e-03]), 'R1': np.float64(420.8327639441094), 'rho': array(1.40719742e-11), 'u': array(0.00168523), 'h': np.float64(46.751229717940966), 'T': np.float64(7037.714879050225), 'kappa': array(8.01356997e+10), 'kappaDust': array(0.), 'srcfunc': array(8.95182968e-14), 'Skapparho': array(1.25888134e-13)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4360 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-1.43135206e+02,  6.48807731e-03,  5.43625638e-03],\n",
      "       [-1.43135206e+02,  6.48807731e-03,  1.00543626e+00]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-1.43135206e+02,  6.48807731e-03,  4.27422433e+02]), 'R1': np.float64(427.4169969622173), 'rho': array(1.05401612e-11), 'u': array(0.00171342), 'h': np.float64(51.47886508855759), 'T': np.float64(6958.551243088252), 'kappa': array(6.24113315e+10), 'kappaDust': array(0.), 'srcfunc': array(8.29748792e-14), 'Skapparho': array(6.18697608e-14)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4358 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-1.43135206e+02,  6.48807731e-03,  5.43625638e-03],\n",
      "       [-1.44135206e+02,  6.48807731e-03,  5.43625638e-03]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-5.62830485e+02,  6.48807731e-03,  5.43625638e-03]), 'R1': np.float64(419.6952789809597), 'rho': array(1.09904837e-11), 'u': array(0.0014338), 'h': np.float64(50.76594169683362), 'T': np.float64(6515.063209793197), 'kappa': array(2.70345995e+10), 'kappaDust': array(0.), 'srcfunc': array(6.38130665e-14), 'Skapparho': array(2.76514113e-14)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4375 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-1.43135206e+02,  6.48807731e-03,  5.43625638e-03],\n",
      "       [-1.43135206e+02, -9.93511923e-01,  5.43625638e-03]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-1.43135206e+02, -4.24372167e+02,  5.43625638e-03]), 'R1': np.float64(424.3786549653609), 'rho': array(1.33535714e-11), 'u': array(0.00151164), 'h': np.float64(47.57501171833648), 'T': np.float64(6754.039114197176), 'kappa': array(4.52614473e+10), 'kappaDust': array(0.), 'srcfunc': array(7.44728375e-14), 'Skapparho': array(5.83184491e-14)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4360 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-1.43135206e+02,  6.48807731e-03,  5.43625638e-03],\n",
      "       [-1.43135206e+02,  6.48807731e-03, -9.94563744e-01]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-1.43135206e+02,  6.48807731e-03, -4.30455225e+02]), 'R1': np.float64(430.4606617020034), 'rho': array(8.01591067e-12), 'u': array(0.00164058), 'h': np.float64(56.39757435331172), 'T': np.float64(6733.876875195873), 'kappa': array(3.60327608e+10), 'kappaDust': array(0.), 'srcfunc': array(7.26308816e-14), 'Skapparho': array(2.1348601e-14)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "*   Note   :    <module>() ==> write_ph_loc_axes() ==> hdf5_dump():\n",
      "\tWriting to ../interm/test_2md_00000.photospherePars.xyz.hdf5  (will OVERWRITE if file already exist.; compress=False)\n",
      "*   Note   :    write_ph_loc_axes() ==> mpdf_read() ==> read():\n",
      "\t\n",
      "\n",
      "\tReading filename='../raw/luis_2md/light_00100'\n",
      "\n",
      "\n",
      "    Debug  :    write_ph_loc_axes() ==> mpdf_read() ==> read():\n",
      "\tudist = 1.00036 solRad\n",
      "\tumass = 1.00035 solMass\n",
      "\tutime = 1.00053 unit_time\n",
      "\tself.time = np.float64(5000.0)\n",
      "self.gamma = np.float64(1.6666666666666667)\n",
      "self.ieos = 10\n",
      "self.total_mass = np.float64(2.3056731566759385)\n",
      "\n",
      "\tCenter of mass location: self.loc_CoM = array([-0.00436207,  0.00763494, -0.00560923])\n",
      "\n",
      "*   Note   :    mpdf_read() ==> read() ==> reset_xyz_by():\n",
      "\tReseting Origin to CoM ([-0.00436207  0.00763494 -0.00560923])...\n",
      "*   Note   :    mpdf_read() ==> read() ==> reset_xyz_by():\n",
      "\tCoM location is now [ 0.00000000e+00 -6.16342983e-15 -8.78770269e-16]\n",
      "**  Warning:    write_ph_loc_axes() ==> mpdf_read() ==> read():\n",
      "\tkappa column exists.\n",
      "\tWe here assume kappa is in phantom units self.units['opacity']=Unit(\"udist2 / umass\") \n",
      "\tHowever in phantom kappa is assumed to be in cgs unit.\n",
      "\tIf so, please CONVERT KAPPA MANNUALLY into PHANTOM units BEFORE proceeding, e.g.:\n",
      "\t\tmpdf.data['gas']['kappa'] = mupl.units_util.get_val_in_unit(\n",
      "\t\tmpdf.data['gas']['kappa'], units.cm**2/units.g, mpdf.units['opacity'])\n",
      "    Debug  :    <module>() ==> write_ph_loc_axes() ==> mpdf_read():\n",
      "\tnp.count_nonzero(mpdf.data['gas']['kappaDust']) = 0\n",
      "\tnp.count_nonzero(mpdf.data['gas']['kappa'])      = 1372088\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4629 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-120.6347532 ,  -78.87378021,    0.24547715],\n",
      "       [-119.6347532 ,  -78.87378021,    0.24547715]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([ 3.99123433e+02, -7.88737802e+01,  2.45477152e-01]), 'R1': np.float64(519.7581866939177), 'rho': array(4.6782928e-12), 'u': array(0.0014587), 'h': np.float64(67.48629438050814), 'T': np.float64(6130.183791408822), 'kappa': array(1.44950192e+10), 'kappaDust': array(0.), 'srcfunc': array(4.48096265e-14), 'Skapparho': array(1.28037652e-14)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4360 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-120.6347532 ,  -78.87378021,    0.24547715],\n",
      "       [-120.6347532 ,  -77.87378021,    0.24547715]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-1.20634753e+02,  3.49639045e+02,  2.45477152e-01]), 'R1': np.float64(428.5128247822477), 'rho': array(3.7220577e-12), 'u': array(0.00146245), 'h': np.float64(72.83112436321743), 'T': np.float64(5987.321916319629), 'kappa': array(9.00408794e+09), 'kappaDust': array(0.), 'srcfunc': array(4.36819307e-14), 'Skapparho': array(4.90433282e-15)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4394 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-120.6347532 ,  -78.87378021,    0.24547715],\n",
      "       [-120.6347532 ,  -78.87378021,    1.24547715]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-120.6347532 ,  -78.87378021,  441.84065557]), 'R1': np.float64(441.5951784185961), 'rho': array(3.71768055e-12), 'u': array(0.00148878), 'h': np.float64(72.85969665238459), 'T': np.float64(6043.694448080177), 'kappa': array(1.19928545e+10), 'kappaDust': array(0.), 'srcfunc': array(4.37118981e-14), 'Skapparho': array(8.82743231e-15)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4629 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-120.6347532 ,  -78.87378021,    0.24547715],\n",
      "       [-121.6347532 ,  -78.87378021,    0.24547715]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-5.76402662e+02, -7.88737802e+01,  2.45477152e-01]), 'R1': np.float64(455.76790833454044), 'rho': array(4.92398339e-12), 'u': array(0.00143806), 'h': np.float64(66.34464206863636), 'T': np.float64(6109.358016967941), 'kappa': array(1.22824916e+10), 'kappaDust': array(0.), 'srcfunc': array(4.67709068e-14), 'Skapparho': array(6.07683007e-15)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4360 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-120.6347532 ,  -78.87378021,    0.24547715],\n",
      "       [-120.6347532 ,  -79.87378021,    0.24547715]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-1.20634753e+02, -5.23507533e+02,  2.45477152e-01]), 'R1': np.float64(444.6337523086637), 'rho': array(4.57649388e-12), 'u': array(0.00155428), 'h': np.float64(67.9830147433044), 'T': np.float64(6338.717797949532), 'kappa': array(1.59078546e+10), 'kappaDust': array(0.), 'srcfunc': array(5.26168657e-14), 'Skapparho': array(6.79614374e-15)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\t4394 particles are close enough to the ray to have effects.\n",
      "    Debug  :    write_ph_loc_axes():\n",
      "\tray = array([[-120.6347532 ,  -78.87378021,    0.24547715],\n",
      "       [-120.6347532 ,  -78.87378021,   -0.75452285]])\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    write_ph_loc_axes() ==> get_photosphere_on_ray() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "    Debug  :    run_code() ==> <module>() ==> write_ph_loc_axes():\n",
      "\tphotosphere = {'is_found': np.True_, 'loc': array([-120.6347532 ,  -78.87378021, -446.21441091]), 'R1': np.float64(446.45988806010905), 'rho': array(3.4885404e-12), 'u': array(0.00144671), 'h': np.float64(74.42122190746393), 'T': np.float64(5904.640004801752), 'kappa': array(1.01869848e+10), 'kappaDust': array(0.), 'srcfunc': array(3.99347011e-14), 'Skapparho': array(5.99827365e-15)}\n",
      "\n",
      "\tlen(taus_waypts) = 4096\n",
      "\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tYou are kernel interpolating density 'rho'.\n",
      "\tConsider using get_rho_from_h() instead to directly calc density from smoothing length, as phantom itself would have done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/sph_interp.py:307: RuntimeWarning: divide by zero encountered in divide\n",
      "  return hfact * (mpart / rho)**(1./ndim)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:469: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_E = np.log10(u)\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: divide by zero encountered in log10\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n",
      "/mnt/d/Sync_OneDrive/Macquarie University/Project RT in CEE - Docs/Projects/20230201/scripts/clmuphantomlib/eos/mesa.py:470: RuntimeWarning: invalid value encountered in subtract\n",
      "  log10_V = 20. + np.log10(rho) - 0.7 * log10_E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappa', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'kappaDust', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'srcfunc', which could lead to problematic results.\n",
      "**  Warning:    <module>() ==> write_ph_loc_axes() ==> get_sph_interp_phantom():\n",
      "\tKernel interpolation should be used with conserved quantities (density, energy, momentum),\n",
      "\tbut you are trying to do it with 'Skapparho', which could lead to problematic results.\n",
      "*   Note   :    <module>() ==> write_ph_loc_axes() ==> hdf5_dump():\n",
      "\tWriting to ../interm/test_2md_00100.photospherePars.xyz.hdf5  (will OVERWRITE if file already exist.; compress=False)\n"
     ]
    }
   ],
   "source": [
    "# main process\n",
    "\n",
    "\n",
    "\n",
    "# init rays directions\n",
    "rays_dir_def = {\n",
    "    # legend: ray direction name\n",
    "    '+x'  : [ 1., 0., 0.],\n",
    "    '+y'  : [ 0., 1., 0.],\n",
    "    '+z'  : [ 0., 0., 1.],\n",
    "    '-x'  : [-1., 0., 0.],\n",
    "    '-y'  : [ 0.,-1., 0.],\n",
    "    '-z'  : [ 0., 0.,-1.],\n",
    "}\n",
    "\n",
    "\n",
    "# run main\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    # get ph loc for each dump file\n",
    "    args = []\n",
    "    for job_profile in JOB_PROFILES:\n",
    "    \n",
    "        file_indexes = job_profile['file_indexes']\n",
    "        #job_name     = job_profile['job_name']\n",
    "        eos          = mupl.get_eos(job_profile['ieos'], job_profile['params'], settings)\n",
    "        eos_opacity  = mupl.eos.mesa.EoS_MESA_opacity(job_profile['params'], settings)\n",
    "    \n",
    "        \n",
    "        if NPROCESSES <= 1:\n",
    "            \n",
    "            # single process\n",
    "    \n",
    "            photosphere_pars = write_ph_loc_axes(\n",
    "                job_profile = job_profile, file_indexes = file_indexes, rays_dir_def = rays_dir_def,\n",
    "                eoses = (eos, eos_opacity), photosphere_tau = PHOTOSPHERE_TAU, verbose = verbose,\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # multi-process\n",
    "\n",
    "            for file_index in file_indexes:\n",
    "                args.append((\n",
    "                    job_profile,\n",
    "                    [file_index],\n",
    "                    rays_dir_def,\n",
    "                    (eos, eos_opacity),\n",
    "                    PHOTOSPHERE_TAU,\n",
    "                    0,\n",
    "                ))\n",
    "                \n",
    "            with Pool(processes=NPROCESSES) as pool:\n",
    "                pool.starmap(write_ph_loc_axes, args)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b2c0d7-7d76-4452-b7e5-c5b1a47f9aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading _metadata__input.json... *   Note   :    run_code() ==> <module>() ==> hdf5_load():\n",
      "\tReading from ../interm/test_2md_00000.photospherePars.xyz.hdf5  (compress=False)\n",
      "Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading _metadata__input.json... *   Note   :    run_code() ==> <module>() ==> hdf5_load():\n",
      "\tReading from ../interm/test_2md_00100.photospherePars.xyz.hdf5  (compress=False)\n",
      "Done.\n",
      "\n",
      "*   Note   :    run_code() ==> <module>() ==> hdf5_dump():\n",
      "\tWriting to ../interm/test_2md.photospherePars.xyz.hdf5  (will OVERWRITE if file already exist.; compress=False)\n",
      "\n",
      "\n",
      "\n",
      "*** All Done. ***\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # syntheize the files into one big file\n",
    "    \n",
    "    for job_profile in JOB_PROFILES:\n",
    "    \n",
    "        job_name     = job_profile['job_name']\n",
    "        file_indexes = job_profile['file_indexes']\n",
    "    \n",
    "    \n",
    "        # init\n",
    "        photosphere_pars_all = { # [legend][par_name][time]\n",
    "            'time_yr': [],\n",
    "            'orbsep_Rsun': [],\n",
    "            'data': {},\n",
    "            'rays_dir': rays_dir_def,\n",
    "            'rays': {},\n",
    "        }  \n",
    "        for key in rays_dir_def.keys():\n",
    "            photosphere_pars_all['data'][key] = {\n",
    "                'size': [],\n",
    "                'R1'  : [],\n",
    "                'rho' : [],\n",
    "                'u'   : [],\n",
    "                'h'   : [],\n",
    "                'T'   : [],\n",
    "                'R1_on_ray' : [],\n",
    "                'tau_on_ray': [],\n",
    "                'rho_on_ray': [],\n",
    "                'u_on_ray'  : [],\n",
    "                'T_on_ray'  : [],\n",
    "            }\n",
    "            photosphere_pars_all['rays'][key] = []\n",
    "    \n",
    "        \n",
    "        # fetch\n",
    "        for file_index in file_indexes:\n",
    "                \n",
    "            if verbose: print(f\"\\n\\nLoading {f.name}... \", end='')\n",
    "            \n",
    "            photosphere_pars = hdf5_load(f\"{interm_dir}{job_profile['nickname']}_{file_index:05}.photospherePars.xyz.hdf5\")\n",
    "            for it in ['time_yr', 'orbsep_Rsun']:\n",
    "                photosphere_pars_all[it].append(photosphere_pars[it])\n",
    "            for key in rays_dir_def.keys():\n",
    "                for it in photosphere_pars_all['data'][key].keys():\n",
    "                    obj = photosphere_pars['data'][key][it]\n",
    "                    if isinstance(obj, np.ndarray):\n",
    "                        obj = obj.tolist()\n",
    "                    photosphere_pars_all['data'][key][it].append(np.asanyarray(obj))\n",
    "                photosphere_pars_all['rays'][key].append(photosphere_pars['rays'][key]) \n",
    "\n",
    "            if verbose: print(f\"Done.\\n\")\n",
    "        \n",
    "        # write\n",
    "        hdf5_dump(\n",
    "            photosphere_pars_all,\n",
    "            f\"{interm_dir}{job_profile['nickname']}.photospherePars.xyz.hdf5\",\n",
    "            metadata=metadata)\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n*** All Done. ***\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
