{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73f1ec5",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cda03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScripts for analyzing of phantom outputs.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Scripts for analyzing of phantom outputs.\n",
    "\n",
    "This script writes json files for each dump (and one json file synthsizing all outputs)\n",
    "    to plot photosphere size vs time or orbital separation.\n",
    "It does so by plotting photosphere intersection with traced rays originating from the primary star\n",
    "    and shooting along the axes of the coordination frame.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30fd6f",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d3ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "#import pandas\n",
    "from astropy import units\n",
    "from astropy import constants as const\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#from moviepy.editor import ImageSequenceClip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d110bbc5-fb24-495d-b62a-33bf01b9a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules listed in ./lib/\n",
    "\n",
    "from lib import clmuphantomlib as mupl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6adf1-b024-4f90-a2b2-d7bb5d154442",
   "metadata": {},
   "source": [
    "    ## import modules in arbitrary directory\n",
    "    \n",
    "    #import sys\n",
    "    \n",
    "    ## path to my python module lib directory\n",
    "    ## *** CHECK THIS! *** #\n",
    "    #SRC_LIB_PATH = sys.path[0] + '/lib'\n",
    "    \n",
    "    #if SRC_LIB_PATH not in sys.path:\n",
    "    #    sys.path.append(SRC_LIB_PATH)\n",
    "    ##print(*sys.path, sep='\\n')    # debug\n",
    "    #print(\n",
    "    #    \"\\n*   Please Make sure my module files are located in this directory (or change the SRC_LIB_PATH variable):\",\n",
    "    #    f\"\\n{SRC_LIB_PATH = }\\n\"\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517d7e50-25fe-4750-8c5b-3e94519c1842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parallels & optimizations\n",
    "\n",
    "\n",
    "#import os\n",
    "## Fixing stupid numba killing kernel\n",
    "## See here https://github.com/numba/numba/issues/3016\n",
    "#os.environ['NUMBA_DISABLE_INTEL_SVML']  = '1'\n",
    "#from numba import njit, prange\n",
    "\n",
    "\n",
    "from multiprocessing import cpu_count, Process, Queue\n",
    "\n",
    "NPROCESSES = cpu_count()\n",
    "if NPROCESSES is None:\n",
    "    NPROCESSES = 1\n",
    "NPROCESSES = max(NPROCESSES, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37d5dde-8b39-4409-9bec-8ae2cabba7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Note: Will use 8 processes for parallelization\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "#\n",
    "#   imported from script_input.py file\n",
    "\n",
    "from script_PhLocAxes__input import iverbose, PHOTOSPHERE_TAU, JOB_PROFILES\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "\n",
    "# print debug info\n",
    "if iverbose >= 2:\n",
    "    print(f\"   Note: Will use {NPROCESSES} processes for parallelization\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4cb2c5-5329-4f4b-bad3-50c869a1512b",
   "metadata": {},
   "source": [
    "    # Test\n",
    "\n",
    "    photosphere_tau = PHOTOSPHERE_TAU\n",
    "    iverbose = 3\n",
    "\n",
    "    job_profile = JOB_PROFILES[0]\n",
    "    job_name = job_profile['job_name']\n",
    "    ieos = job_profile['ieos']\n",
    "    file_indexes = job_profile['file_indexes']\n",
    "    plot_title_suffix = job_profile['plot_title_suffix']\n",
    "    X = job_profile['X']\n",
    "\n",
    "\n",
    "    file_index=file_indexes[5]\n",
    "    mpdf = mupl.MyPhantomDataFrames()\n",
    "    mpdf.read(\n",
    "        job_name, file_index,\n",
    "        calc_params=['T', 'kappa', 'R1'],\n",
    "        reset_xyz_by=\"R1\",\n",
    "        calc_params_params={'ieos': ieos, 'X':X, 'overwrite':False, 'kappa_translate_from_cgs_units':True},\n",
    "        iverbose=iverbose,\n",
    "    )\n",
    "    mpdf.plot_render(plot_title_suffix=plot_title_suffix,\n",
    "        xlim=(-60000, 60000), ylim=(-60000, 60000),\n",
    "        norm=mpl.colors.LogNorm(vmin=1e-25, vmax=1e-5, clip=True),\n",
    "    )\n",
    "    if iverbose:\n",
    "        print()\n",
    "        print(mpdf.get_time())\n",
    "        print(mpdf.data['gas'].keys())\n",
    "        print(mpdf.data['sink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea03f49-8b8b-481a-9b54-3631e8164b5f",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    # units info (for plot axes title)\n",
    "    \n",
    "    unitsIn = {    # not used for reading phantom data dumps since it records units in the dump already\n",
    "        'dist': units.solRad,\n",
    "        'temp': units.K,\n",
    "        'flux': units.erg/units.cm**2/units.s,    # equivalent of units.g/units.s**3\n",
    "        'opacity': units.cm**2/units.g,\n",
    "    }\n",
    "    \n",
    "    unitsOut = {\n",
    "        'dist': units.solRad,\n",
    "        'temp': units.K,\n",
    "        'flux': units.erg/units.cm**2/units.s,    # equivalent of units.g/units.s**3\n",
    "        'opacity': units.cm**2/units.g,\n",
    "    }\n",
    "    \n",
    "    unitsOutTxt = {}\n",
    "    \n",
    "    for key in unitsOut.keys():\n",
    "        unitsOutTxt[key] = unitsOut[key].to_string('latex_inline')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40466d2f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f063ed6",
   "metadata": {},
   "source": [
    "## Photosphere size vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8132b3-209d-4680-b364-d9d5eb4cb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ph_loc_axes(\n",
    "    job_profile : dict,\n",
    "    file_indexes : np.ndarray,\n",
    "    rays_dir_def : dict,    # dict of list\n",
    "    photosphere_tau = PHOTOSPHERE_TAU,\n",
    "    iverbose : int = 2,\n",
    "):\n",
    "\n",
    "    \"\"\"Writing the photosphere locations of each dump to json files.\n",
    "\n",
    "    Notes:\n",
    "    Using mpdf.params['hfact']\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mpdf = mupl.MyPhantomDataFrames()\n",
    "\n",
    "    \n",
    "    job_name = job_profile['job_name']\n",
    "    X = job_profile['X']\n",
    "    ieos = job_profile['ieos']\n",
    "\n",
    "    \n",
    "    # init rays directions\n",
    "    rays_dir = {}\n",
    "    for key in rays_dir_def.keys():\n",
    "        rays_dir[key] = np.array(rays_dir_def[key])\n",
    "\n",
    "\n",
    "    # main\n",
    "    for file_index in file_indexes:\n",
    "        \n",
    "        # init answer dict / array\n",
    "        photosphere_pars = { # [legend][par_name][time]\n",
    "            'time_yr': None,\n",
    "            'orbsep_Rsun': None,\n",
    "            'data': {},\n",
    "            'rays_dir': rays_dir_def,\n",
    "            'rays': {},\n",
    "        }  \n",
    "        for key in rays_dir.keys():\n",
    "            photosphere_pars['data'][key] = {\n",
    "                'size': None,\n",
    "                'rho' : None,\n",
    "                'u'   : None,\n",
    "                'h'   : None,\n",
    "                'T'   : None,\n",
    "            }\n",
    "\n",
    "        # read data\n",
    "        mpdf.read(job_name, file_index, reset_xyz_by='CoM', iverbose=iverbose)\n",
    "        if 'Tdust' in mpdf.data['gas'].columns:\n",
    "            mpdf.data['gas']['T'] = mpdf.data['gas']['Tdust']\n",
    "        elif 'temperature' in mpdf.data['gas'].columns:\n",
    "            mpdf.data['gas']['T'] = mpdf.data['gas']['temperature']\n",
    "        mpdf.calc_sdf_params(\n",
    "            calc_params=['T', 'kappa',], #'R1',\n",
    "            calc_params_params={'ieos': ieos, 'X':X, 'overwrite':False, 'kappa_translate_from_cgs_units':True},\n",
    "            iverbose=iverbose,\n",
    "        )\n",
    "        hfact = mpdf.params['hfact']\n",
    "        mpart = mpdf.params['mass']\n",
    "        \n",
    "        photosphere_pars['time_yr'] = mpdf.get_time().to_value(units.year)\n",
    "        photosphere_pars['orbsep_Rsun'] = mpdf.get_orb_sep().to_value(units.Rsun)\n",
    "\n",
    "        # construct rays_dict\n",
    "        star_loc = np.array([mpdf.data['sink'][axis][0] for axis in 'xyz'])\n",
    "        rays_dict = {}    # legend: ray\n",
    "        for key in rays_dir.keys():\n",
    "            # init\n",
    "            ray = np.array([\n",
    "                star_loc,\n",
    "                star_loc + rays_dir[key],\n",
    "            ])\n",
    "            rays_dict[key] = ray\n",
    "            photosphere_pars['rays'][key] = ray.tolist()\n",
    "            ray_unit_vec = ray[1, :] - ray[0, :]\n",
    "            ray_unit_vec = ray_unit_vec / np.sum(ray_unit_vec**2)**0.5\n",
    "\n",
    "\n",
    "            # optimization- first select only the particles affecting the ray\n",
    "            #  because interpolation of m points with N particles scales with O(N*m),\n",
    "            #  reducing N can speed up calc significantly\n",
    "            sdf = mpdf.data['gas']\n",
    "            kernel_radius = sdf.kernel.get_radius()\n",
    "            hs = np.array(sdf['h'])\n",
    "            pts = np.array(sdf[['x', 'y', 'z']])    # (npart, 3)-shaped array\n",
    "            pts_on_ray = mupl.get_closest_pt_on_line(pts, ray)\n",
    "            sdf_selected_indices = (np.sum((pts - pts_on_ray)**2, axis=-1) <= (kernel_radius * hs)**2)\n",
    "            if iverbose >= 3:\n",
    "                print(f\"    Info: {np.count_nonzero(sdf_selected_indices)} particles are close enough to the ray to have effects.\")\n",
    "            sdf = sdf.iloc[sdf_selected_indices]\n",
    "            pts = np.array(sdf[['x', 'y', 'z']])    # (npart, 3)-shaped array\n",
    "\n",
    "\n",
    "            # get optical depth\n",
    "            if iverbose >= 3: print(f\"    Info: {ray = }\")\n",
    "            pts_on_ray, dtaus, pts_order = mupl.get_optical_depth_by_ray_tracing_3D(sdf=sdf, ray=ray)\n",
    "            pts_order_nonzero = np.where(dtaus[pts_order])[0]\n",
    "            if iverbose >= 3:\n",
    "                print(f\"    Info: {pts_order_nonzero.size = }\")\n",
    "            pts_on_ray_ordered = pts_on_ray[pts_order]\n",
    "            dist_to_ray0_ordered = np.sum((pts_on_ray_ordered - ray[0]) * ray_unit_vec, axis=-1)\n",
    "            taus_ordered = np.cumsum(dtaus[pts_order])\n",
    "\n",
    "\n",
    "            # get photosphere\n",
    "            photosphere_loc_index = np.searchsorted(taus_ordered, photosphere_tau) - 1\n",
    "            photosphere_found = photosphere_loc_index <= len(sdf) - 2\n",
    "            if photosphere_found:\n",
    "                if photosphere_loc_index == -1:\n",
    "                    # if first particle blocks everything: estimate it to be where that particle is\n",
    "                    photosphere_loc_index = 0\n",
    "                    photosphere_loc = pts_on_ray_ordered[0]\n",
    "                    photosphere_taus = [0., taus_ordered[photosphere_loc_index]]    # for debug\n",
    "                else:\n",
    "                    # intepolate to find loc\n",
    "                    photosphere_taus = taus_ordered[photosphere_loc_index : photosphere_loc_index+2]\n",
    "                    photosphere_dtau = photosphere_taus[1] - photosphere_taus[0]\n",
    "                    photosphere_dtau0_frac = (photosphere_taus[1] - photosphere_tau) / photosphere_dtau\n",
    "                    photosphere_loc = \\\n",
    "                        pts_on_ray_ordered[photosphere_loc_index] * photosphere_dtau0_frac + \\\n",
    "                        pts_on_ray_ordered[photosphere_loc_index+1] * (1 - photosphere_dtau0_frac)\n",
    "                photosphere_dist_to_ray0 = np.sum((photosphere_loc - ray[0]) * ray_unit_vec, axis=-1)\n",
    "\n",
    "\n",
    "                photosphere_rho = mupl.get_sph_interp(sdf, 'rho' , photosphere_loc)\n",
    "                photosphere_u   = mupl.get_sph_interp(sdf, 'u'   , photosphere_loc)\n",
    "                \n",
    "                photosphere_pars['data'][key]['size'] = photosphere_dist_to_ray0\n",
    "                photosphere_pars['data'][key]['rho' ] = photosphere_rho\n",
    "                photosphere_pars['data'][key]['u'   ] = photosphere_u\n",
    "                photosphere_pars['data'][key]['h'   ] = hfact * (mpart / photosphere_rho)**(1./3.)\n",
    "                photosphere_pars['data'][key]['T'   ] = mupl.get_temp_from_u(\n",
    "                    rho=photosphere_rho, u=photosphere_u, mu=None, ieos=ieos,\n",
    "                    rho_unit=mpdf.units['density'], u_unit=mpdf.units['specificEnergy'],\n",
    "                ).item()\n",
    "                \n",
    "                if iverbose >= 3:\n",
    "                    print(    # debug\n",
    "                        f\"{photosphere_loc = }\\n{photosphere_dist_to_ray0 = }\\n\",\n",
    "                        f\"{photosphere_taus = }\\n\",\n",
    "                        f\"{pts_on_ray_ordered[photosphere_loc_index:photosphere_loc_index+2] = }\",\n",
    "                    )\n",
    "            else:\n",
    "                if iverbose: print(f\"*    Warning: Photosphere not found ({photosphere_loc_index=}; {max(taus_ordered)=})\")\n",
    "            \n",
    "        with open(f\"{mpdf.get_filename()}__photospherePars__xyz.json\", 'w') as f:\n",
    "            json.dump(photosphere_pars, f)\n",
    "            if iverbose: print(f\"\\n\\nWritten to {f.name}\\n\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951dd520-ce47-42ce-9b21-f4f1951e1cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main process\n",
    "\n",
    "\n",
    "\n",
    "# init rays directions\n",
    "rays_dir_def = {\n",
    "    # legend: ray direction name\n",
    "    '+x'  : [ 1., 0., 0.],\n",
    "    '+y'  : [ 0., 1., 0.],\n",
    "    '+z'  : [ 0., 0., 1.],\n",
    "    '-x'  : [-1., 0., 0.],\n",
    "    '-y'  : [ 0.,-1., 0.],\n",
    "    '-z'  : [ 0., 0.,-1.],\n",
    "}\n",
    "\n",
    "\n",
    "# run main\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    # get ph loc for each dump file\n",
    "    for job_profile in JOB_PROFILES:\n",
    "    \n",
    "        file_indexes = job_profile['file_indexes']\n",
    "    \n",
    "        \n",
    "        if NPROCESSES <= 1:\n",
    "            \n",
    "            # single process\n",
    "    \n",
    "            write_ph_loc_axes(\n",
    "                job_profile = job_profile, file_indexes = file_indexes, rays_dir_def = rays_dir_def,\n",
    "                photosphere_tau = PHOTOSPHERE_TAU, iverbose = 0,\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # multi-process\n",
    "            \n",
    "            file_indexes_list = np.array_split(file_indexes, NPROCESSES)\n",
    "            processes_list = []\n",
    "            for i, file_indexes in enumerate(file_indexes_list):\n",
    "                processes_list.append(\n",
    "                    Process(\n",
    "                        target=write_ph_loc_axes,\n",
    "                        kwargs={'job_profile': job_profile, 'file_indexes': file_indexes, 'rays_dir_def': rays_dir_def,\n",
    "                                'photosphere_tau': PHOTOSPHERE_TAU, 'iverbose': 0,\n",
    "                        },\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "            for process in processes_list:\n",
    "                process.start()\n",
    "        \n",
    "            for process in processes_list:\n",
    "                process.join()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b2c0d7-7d76-4452-b7e5-c5b1a47f9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_00000__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_00396__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_00792__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_01188__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_01584__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_01980__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_02178__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_02376__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_02574__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_02772__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_03564__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_04710__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_05780__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_07090__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_2md/binary_08000__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Written to ../photosphere/luis_2md/binary__photospherePars__xyz.json.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_00000__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_00396__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_00792__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_01188__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_01584__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_01980__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_02178__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_02277__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_02376__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_02574__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_02772__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_03564__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_04710__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_05780__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_07090__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_08000__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_11880__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_15840__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_17820__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Loading ../photosphere/luis_4md/binary_19800__photospherePars__xyz.json... Done.\n",
      "\n",
      "\n",
      "\n",
      "Written to ../photosphere/luis_4md/binary__photospherePars__xyz.json.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # syntheize the files into one big file\n",
    "    \n",
    "    for job_profile in JOB_PROFILES:\n",
    "    \n",
    "        job_name     = job_profile['job_name']\n",
    "        file_indexes = job_profile['file_indexes']\n",
    "    \n",
    "    \n",
    "        # init\n",
    "        photosphere_pars_all = { # [legend][par_name][time]\n",
    "            'time_yr': [],\n",
    "            'orbsep_Rsun': [],\n",
    "            'data': {},\n",
    "            'rays_dir': rays_dir_def,\n",
    "            'rays': {},\n",
    "        }  \n",
    "        for key in rays_dir_def.keys():\n",
    "            photosphere_pars_all['data'][key] = {\n",
    "                'size': [],\n",
    "                'rho' : [],\n",
    "                'u'   : [],\n",
    "                'h'   : [],\n",
    "                'T'   : [],\n",
    "            }\n",
    "            photosphere_pars_all['rays'][key] = []\n",
    "    \n",
    "        \n",
    "        # fetch\n",
    "        for file_index in file_indexes:\n",
    "            with open(f\"{job_name}_{file_index:05}__photospherePars__xyz.json\", 'r') as f:\n",
    "                \n",
    "                if iverbose: print(f\"\\n\\nLoading {f.name}... \", end='')\n",
    "                \n",
    "                photosphere_pars = json.load(f)\n",
    "                for it in ['time_yr', 'orbsep_Rsun']:\n",
    "                    photosphere_pars_all[it].append(photosphere_pars[it])\n",
    "                for key in rays_dir_def.keys():\n",
    "                    for it in photosphere_pars_all['data'][key].keys():\n",
    "                        photosphere_pars_all['data'][key][it].append(photosphere_pars['data'][key][it])\n",
    "                    photosphere_pars_all['rays'][key].append(photosphere_pars['rays'][key]) \n",
    "    \n",
    "                if iverbose: print(f\"Done.\\n\")\n",
    "    \n",
    "        \n",
    "        # write\n",
    "        with open(f\"{job_name}__photospherePars__xyz.json\", 'w') as f:\n",
    "            json.dump(photosphere_pars_all, f)\n",
    "            if iverbose: print(f\"\\n\\nWritten to {f.name}.\\n\")\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n*** All Done. ***\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
